{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GBV_Sentiment Analysis_Modelling.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNUwrOJo0cch24ckoSw1PjU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Paul-mwaura/Gender-Based-Discrimination-NLP/blob/main/GBV_Sentiment_Analysis_Modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VQjMsbBJ_Tn"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn import decomposition, ensemble\n",
        "\n",
        "import pandas, xgboost, numpy, textblob, string\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "QsxeHYhYKQLg",
        "outputId": "82e7973a-98da-432d-d03e-02606f9dfe3f"
      },
      "source": [
        "df = pd.read_csv(\"/content/GBV_data_clean_v04.csv\")\n",
        "df.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>username</th>\n",
              "      <th>new_tweets</th>\n",
              "      <th>clean_tweets</th>\n",
              "      <th>tweets_without_stopwords</th>\n",
              "      <th>replies</th>\n",
              "      <th>retweets</th>\n",
              "      <th>likes</th>\n",
              "      <th>pol_nltk</th>\n",
              "      <th>nltk_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>2keercous</td>\n",
              "      <td>Didn't he sxually assault a woman</td>\n",
              "      <td>didnt he sxually assault a woman</td>\n",
              "      <td>didnt sxually assault woman</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.494, 'pos': 0.506}</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>26</td>\n",
              "      <td>27</td>\n",
              "      <td>imshanereaction</td>\n",
              "      <td>And for the love of God please no more pictur...</td>\n",
              "      <td>and for the love of god please no more pictur...</td>\n",
              "      <td>love god please pictures man groping woman lik...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.419, 'pos': 0.581}</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>64</td>\n",
              "      <td>65</td>\n",
              "      <td>preconciliatio1</td>\n",
              "      <td>. lol</td>\n",
              "      <td>lol</td>\n",
              "      <td>lol</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>{'neg': 0.0, 'neu': 0.0, 'pos': 1.0}</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  ...  nltk_sentiment\n",
              "0          12  ...             pos\n",
              "1          26  ...             pos\n",
              "2          64  ...             pos\n",
              "\n",
              "[3 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "PIS07YnPKzLk",
        "outputId": "d351e442-f87b-473a-9921-bca6fd76dc6a"
      },
      "source": [
        "df = df[['tweets_without_stopwords', 'nltk_sentiment']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweets_without_stopwords</th>\n",
              "      <th>nltk_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>didnt sxually assault woman</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>love god please pictures man groping woman lik...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lol</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>agree cant attack assault someone exactly woma...</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>dm ok said seem like lovely man lets chat</td>\n",
              "      <td>pos</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            tweets_without_stopwords nltk_sentiment\n",
              "0                        didnt sxually assault woman            pos\n",
              "1  love god please pictures man groping woman lik...            pos\n",
              "2                                                lol            pos\n",
              "3  agree cant attack assault someone exactly woma...            pos\n",
              "4          dm ok said seem like lovely man lets chat            pos"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmMwwXKfLAp7",
        "outputId": "718f65a3-c07f-4666-b17b-d6dfc4948f62"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tweets_without_stopwords    0\n",
              "nltk_sentiment              0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRR9mTFvLDJj",
        "outputId": "3d1604bd-4fec-453c-9b8a-ab9cef766321"
      },
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNnXZIALLGho",
        "outputId": "10cb01e6-a254-4ecf-8f02-905c03ecd78a"
      },
      "source": [
        "df.drop_duplicates(inplace=True)\n",
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lwft6WBQLMzR",
        "outputId": "d67738d6-74e6-4bbd-b5c0-e19a1d093b45"
      },
      "source": [
        "df.groupby(['nltk_sentiment'])['nltk_sentiment'].count().sort_values(ascending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nltk_sentiment\n",
              "neg    1320\n",
              "pos    1350\n",
              "neu    1365\n",
              "Name: nltk_sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aBM3TtteMIMW"
      },
      "source": [
        "### Split the data into Features and Labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhVv_t-LMD5c"
      },
      "source": [
        "# split the dataset into training and validation datasets \n",
        "X_train, X_valid, y_train, y_valid = model_selection.train_test_split(df['tweets_without_stopwords'], df['nltk_sentiment'])\n",
        "\n",
        "# label encode the target variable \n",
        "encoder = preprocessing.LabelEncoder()\n",
        "y_train = encoder.fit_transform(y_train)\n",
        "y_valid = encoder.fit_transform(y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdnEijI6KAdl"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqE_lpexMcQG"
      },
      "source": [
        "### Count Vectors as features\n",
        "Count Vector is a matrix notation of the dataset in which every row represents a document from the corpus, every column represents a term from the corpus, and every cell represents the frequency count of a particular term in a particular document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYavzx5UMZat"
      },
      "source": [
        "# create a count vectorizer object \n",
        "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
        "count_vect.fit(df['tweets_without_stopwords'])\n",
        "\n",
        "# transform the training and validation data using count vectorizer object\n",
        "xtrain_count =  count_vect.transform(X_train)\n",
        "xvalid_count =  count_vect.transform(X_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OqUZV8rMrDB"
      },
      "source": [
        "### TF-IDF Vectors as features\n",
        ">>\n",
        "* TF(t) = (Number of times term t appears in a document) / (Total number of terms in the document)\n",
        "* IDF(t) = log_e(Total number of documents / Number of documents with term t in it)\n",
        "\n",
        ">>\n",
        "TF-IDF Vectors can be generated at different levels of input tokens (words, characters, n-grams)\n",
        "* a. Word Level TF-IDF : Matrix representing tf-idf scores of every term in different documents\n",
        "* b. N-gram Level TF-IDF : N-grams are the combination of N terms together. This Matrix representing tf-idf scores of N-grams\n",
        "* c. Character Level TF-IDF : Matrix representing tf-idf scores of character level n-grams in the corpus"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OnQEWzFMfbe",
        "outputId": "ee074450-ec95-419b-a9b3-a65f51637347"
      },
      "source": [
        "# word level tf-idf\n",
        "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
        "tfidf_vect.fit(df['tweets_without_stopwords'])\n",
        "xtrain_tfidf =  tfidf_vect.transform(X_train)\n",
        "xvalid_tfidf =  tfidf_vect.transform(X_valid)\n",
        "\n",
        "# ngram level tf-idf \n",
        "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram.fit(df['tweets_without_stopwords'])\n",
        "xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(X_train)\n",
        "xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(X_valid)\n",
        "\n",
        "# characters level tf-idf\n",
        "tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
        "tfidf_vect_ngram_chars.fit(df['tweets_without_stopwords'])\n",
        "xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_train) \n",
        "xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(X_valid) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:547: UserWarning: The parameter 'token_pattern' will not be used since 'analyzer' != 'word'\n",
            "  \"The parameter 'token_pattern' will not be used\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqEA17JQQXdU"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FmktdChYMzTz"
      },
      "source": [
        "def train_model(classifier, feature_vector_train, label, feature_vector_valid, is_neural_net=False):\n",
        "    # fit the training dataset on the classifier\n",
        "    classifier.fit(feature_vector_train, label)\n",
        "    \n",
        "    # predict the labels on validation dataset\n",
        "    predictions = classifier.predict(feature_vector_valid)\n",
        "    \n",
        "    if is_neural_net:\n",
        "        predictions = predictions.argmax(axis=-1)\n",
        "    \n",
        "    return metrics.accuracy_score(predictions, y_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJihBzEjQg2m"
      },
      "source": [
        "### Naive Bayes\n",
        "Naive Bayes is a classification technique based on Bayesâ€™ Theorem with an assumption of independence among predictors. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLQTg6KaQdQq",
        "outputId": "35faf064-c9f6-484d-9e79-26e8892ae5d4"
      },
      "source": [
        "# Naive Bayes\n",
        "print(\"Naive Bayes\\n\")\n",
        "# Naive Bayes on Count Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_count, y_train, xvalid_count)\n",
        "print(\"Count Vectors: \", accuracy*100)\n",
        "\n",
        "# Naive Bayes on Word Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xvalid_tfidf)\n",
        "print(\"WordLevel TF-IDF: \", accuracy*100)\n",
        "\n",
        "# Naive Bayes on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, y_train, xvalid_tfidf_ngram)\n",
        "print(\"N-Gram Vectors: \", accuracy*100)\n",
        "\n",
        "# Naive Bayes on Character Level TF IDF Vectors\n",
        "accuracy = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram_chars, y_train, xvalid_tfidf_ngram_chars)\n",
        "print(\"CharLevel Vectors: \", accuracy*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes\n",
            "\n",
            "Count Vectors:  71.55599603567889\n",
            "WordLevel TF-IDF:  75.02477700693755\n",
            "N-Gram Vectors:  56.987115956392465\n",
            "CharLevel Vectors:  67.78989098116948\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOhmx5HMQqKK"
      },
      "source": [
        "### Linear Classifier (Logistic Regression)\n",
        "Logistic regression measures the relationship between the categorical dependent variable and one or more independent variables by estimating probabilities using a logistic/sigmoid function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drGIWUyWQmcr",
        "outputId": "f681b5fe-34da-42f3-f56a-e549e2fc8df3"
      },
      "source": [
        "# Linear Regression \n",
        "print(\"Linear Regression\\n\")\n",
        "\n",
        "lr = linear_model.LogisticRegression()\n",
        "\n",
        "# Linear Classifier on Count Vectors\n",
        "accuracy = train_model(lr, xtrain_count, y_train, xvalid_count)\n",
        "print(\"Count Vectors: \", accuracy*100)\n",
        "\n",
        "# Linear Classifier on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(lr, xtrain_tfidf_ngram, y_train, xvalid_tfidf_ngram)\n",
        "print(\"N-Gram Vectors: \", accuracy*100)\n",
        "\n",
        "# Linear Classifier on Character Level TF IDF Vectors\n",
        "accuracy = train_model(lr, xtrain_tfidf_ngram_chars, y_train, xvalid_tfidf_ngram_chars)\n",
        "print(\"CharLevel Vectors: \", accuracy*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression\n",
            "\n",
            "Count Vectors:  78.49355797819624\n",
            "N-Gram Vectors:  57.97819623389494\n",
            "CharLevel Vectors:  73.6372646184341\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6eTLn47BS3Kk"
      },
      "source": [
        "## Save Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrCj6-44S7e6"
      },
      "source": [
        "### TIdf Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMbzVcntSbMo",
        "outputId": "94e51f3d-f375-4b42-f90e-325dd4b4b5a1"
      },
      "source": [
        "import pickle, joblib\n",
        "# Linear Classifier on Word Level TF IDF Vectors\n",
        "accuracy = train_model(lr, xtrain_tfidf, y_train, xvalid_tfidf)\n",
        "print(\"WordLevel TF-IDF: \", accuracy*100)\n",
        "\n",
        "# Save the model as Pickle File\n",
        "with open('tfidf_model.pickle', 'wb') as handle:\n",
        "    pickle.dump(lr, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# Save the model as Joblib file\n",
        "filename = 'tfidf_model.joblib'\n",
        "joblib.dump(lr, filename)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WordLevel TF-IDF:  78.09712586719525\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tfidf_model.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iloF9xyLQyc1"
      },
      "source": [
        "### Implementing a SVM Model\n",
        "Support Vector Machine (SVM) is a supervised machine learning algorithm which can be used for both classification or regression challenges. The model extracts a best possible hyper-plane / line that segregates the two classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjbJJVSuQuFj",
        "outputId": "2e5693a1-385c-4198-d994-56a25bcc0647"
      },
      "source": [
        "# SVM on Ngram Level TF IDF Vectors\n",
        "accuracy = train_model(svm.SVC(), xtrain_tfidf_ngram, y_train, xvalid_tfidf_ngram)\n",
        "print(\"SVM, N-Gram Vectors: \", accuracy*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM, N-Gram Vectors:  55.50049554013875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8PG6a6LQ6pf"
      },
      "source": [
        "### Bagging Model (Random Forest Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fg_9LotjQ3kb",
        "outputId": "83bdc6fe-86c5-44fe-fd04-9e14e9dd8955"
      },
      "source": [
        "# Random Forest Model\n",
        "print(\"Random Forest Model\")\n",
        "# RF on Count Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_count, y_train, xvalid_count)\n",
        "print(\"Count Vectors: \", accuracy*100)\n",
        "\n",
        "# RF on Word Level TF IDF Vectors\n",
        "accuracy = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, y_train, xvalid_tfidf)\n",
        "print(\"WordLevel TF-IDF: \", accuracy*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model\n",
            "Count Vectors:  68.18632309217047\n",
            "WordLevel TF-IDF:  68.97918731417245\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkZEYUleRUpI"
      },
      "source": [
        "### Boosting Model (Xtreme Gradient Boosting Model)\n",
        "Boosting is a machine learning ensemble meta-algorithm for primarily reducing bias, and also variance in supervised learning, and a family of machine learning algorithms that convert weak learners to strong ones. \n",
        "\n",
        "A weak learner is defined to be a classifier that is only slightly correlated with the true classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9UwypPdQ9op",
        "outputId": "b05e9244-77e6-481a-ddf8-abe82554e91d"
      },
      "source": [
        "# XGB Model\n",
        "print(\"XGB Model\\n\")\n",
        "# Extereme Gradient Boosting on Count Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), y_train, xvalid_count.tocsc())\n",
        "print(\"Count Vectors: \", accuracy*100)\n",
        "\n",
        "# Extereme Gradient Boosting on Word Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), y_train, xvalid_tfidf.tocsc())\n",
        "print(\"WordLevel TF-IDF: \", accuracy*100)\n",
        "\n",
        "# Extereme Gradient Boosting on Character Level TF IDF Vectors\n",
        "accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), y_train, xvalid_tfidf_ngram_chars.tocsc())\n",
        "print(\"CharLevel Vectors: \", accuracy*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGB Model\n",
            "\n",
            "Count Vectors:  66.10505450941527\n",
            "WordLevel TF-IDF:  67.29435084241824\n",
            "CharLevel Vectors:  67.29435084241824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy8AhF7ER4S1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bM_lLZYtRXOs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}